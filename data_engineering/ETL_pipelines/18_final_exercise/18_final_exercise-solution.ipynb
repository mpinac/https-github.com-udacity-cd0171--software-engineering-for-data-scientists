{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exercise - Putting it All Together\n",
    "\n",
    "In this last exercise, you'll write a full ETL pipeline for the GDP data. That means you'll extract the World Bank data, transform the data, and load the data all in one go. In other words, you'll want one Python script that can do the entire process.\n",
    "\n",
    "Why would you want to do this? Imagine working for a company that creates new data every day. As new data comes in, you'll want to write software that periodically and automatically extracts, transforms, and loads the data.\n",
    "\n",
    "To give you a sense for what this is like, you'll extract the GDP data one line at a time. You'll then transform that line of data and load the results into a SQLite database. The code in this exercise is somewhat tricky.\n",
    "\n",
    "Here is an explanation of how this Jupyter notebook is organized:\n",
    "1. The first cell connects to a SQLite database called worldbank.db and creates a table to hold the gdp data. You do not need to do anything in this code cell other than executing the cell.\n",
    "2. The second cell has a function called extract_line(). You don't need to do anything in this code cell either besides executing the cell. This function is a [Python generator](https://wiki.python.org/moin/Generators). You don't need to understand how this works in order to complete the exercise. Essentially, a generator is like a regular function except instead of a return statement, a generator has a yield statement. Generators allow you to use functions in a for loop. In essence, this function will allow you to read in a data file one line at a time, run a transformation on that row of data, and then move on to the next row in the file.\n",
    "3. The third cell contains a function called transform_indicator_data(). This function receives a line from the csv file and transforms the data in preparation for a load step.\n",
    "4. The fourth cell contains a function called load_indicator_data(), which loads the trasnformed data into the gdp table in the worldbank.db database.\n",
    "5. The fifth cell runs the ETL pipeilne\n",
    "6. The sixth cell runs a query against the database to make sure everything worked correctly.\n",
    "\n",
    "You'll need to modify the third and fourth cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to create a database and a table, called gdp, to hold the gdp data\n",
    "# You do not need to change anything in this code cell\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# connect to the database\n",
    "# the database file will be worldbank.db\n",
    "# note that sqlite3 will create this database file if it does not exist already\n",
    "conn = sqlite3.connect('worldbank.db')\n",
    "\n",
    "# get a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# drop the test table in case it already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS gdp\")\n",
    "\n",
    "# create the test table including project_id as a primary key\n",
    "cur.execute(\"CREATE TABLE gdp (countryname TEXT, countrycode TEXT, year INTEGER, gdp REAL, PRIMARY KEY (countrycode, year));\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator for reading in one line at a time\n",
    "# generators are useful for data sets that are too large to fit in RAM\n",
    "# You do not need to change anything in this code cell\n",
    "def extract_lines(file):\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill out the code wherever you find a TODO in this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# transform the indicator data\n",
    "def transform_indicator_data(data, colnames):\n",
    "    \n",
    "    # get rid of quote marks\n",
    "    for i, datum in enumerate(data):\n",
    "        data[i] = datum.replace('\"','')\n",
    "    \n",
    "    country = data[0]\n",
    "    \n",
    "    # filter out values that are not countries\n",
    "    non_countries = ['World',\n",
    "     'High income',\n",
    "     'OECD members',\n",
    "     'Post-demographic dividend',\n",
    "     'IDA & IBRD total',\n",
    "     'Low & middle income',\n",
    "     'Middle income',\n",
    "     'IBRD only',\n",
    "     'East Asia & Pacific',\n",
    "     'Europe & Central Asia',\n",
    "     'North America',\n",
    "     'Upper middle income',\n",
    "     'Late-demographic dividend',\n",
    "     'European Union',\n",
    "     'East Asia & Pacific (excluding high income)',\n",
    "     'East Asia & Pacific (IDA & IBRD countries)',\n",
    "     'Euro area',\n",
    "     'Early-demographic dividend',\n",
    "     'Lower middle income',\n",
    "     'Latin America & Caribbean',\n",
    "     'Latin America & the Caribbean (IDA & IBRD countries)',\n",
    "     'Latin America & Caribbean (excluding high income)',\n",
    "     'Europe & Central Asia (IDA & IBRD countries)',\n",
    "     'Middle East & North Africa',\n",
    "     'Europe & Central Asia (excluding high income)',\n",
    "     'South Asia (IDA & IBRD)',\n",
    "     'South Asia',\n",
    "     'Arab World',\n",
    "     'IDA total',\n",
    "     'Sub-Saharan Africa',\n",
    "     'Sub-Saharan Africa (IDA & IBRD countries)',\n",
    "     'Sub-Saharan Africa (excluding high income)',\n",
    "     'Middle East & North Africa (excluding high income)',\n",
    "     'Middle East & North Africa (IDA & IBRD countries)',\n",
    "     'Central Europe and the Baltics',\n",
    "     'Pre-demographic dividend',\n",
    "     'IDA only',\n",
    "     'Least developed countries: UN classification',\n",
    "     'IDA blend',\n",
    "     'Fragile and conflict affected situations',\n",
    "     'Heavily indebted poor countries (HIPC)',\n",
    "     'Low income',\n",
    "     'Small states',\n",
    "     'Other small states',\n",
    "     'Not classified',\n",
    "     'Caribbean small states',\n",
    "     'Pacific island small states']\n",
    "    \n",
    "    if country not in non_countries:\n",
    "        data_array = np.array(data, ndmin=2)\n",
    "        data_array.reshape(1, 63)\n",
    "        df = pd.DataFrame(data_array, columns=colnames).replace('', np.nan)\n",
    "        df.drop(['\\r\\n', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
    "\n",
    "        # Reshape the data sets so that they are in long format\n",
    "        df_melt = df.melt(id_vars=['Country Name', 'Country Code'], \n",
    "                            var_name='year', \n",
    "                            value_name='gdp')\n",
    "        \n",
    "        results = []\n",
    "        for index, row in df_melt.iterrows():\n",
    "            country, countrycode, year, gdp = row\n",
    "            if str(gdp) != 'nan':\n",
    "                results.append([country, countrycode, year, gdp])\n",
    "        return results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill out the code wherever you find a TODO in this cell\n",
    "\n",
    "def load_indicator_data(results):\n",
    "    conn = sqlite3.connect('worldbank.db')\n",
    "    cur = conn.cursor()\n",
    "    if results:\n",
    "        for result in results:\n",
    "            countryname, countrycode, year, gdp = result\n",
    "\n",
    "            sql_string = 'INSERT INTO gdp (countryname, countrycode, year, gdp) VALUES (\"{}\", \"{}\", {}, {});'.format(countryname, countrycode, year, gdp)\n",
    "\n",
    "            # connect to database and execute query\n",
    "            try:\n",
    "                cur.execute(sql_string)\n",
    "            except Exception as e:\n",
    "                print('error occurred:', e, result)\n",
    "            \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['\\\\r\\\\n'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m         colnames\u001b[39m.\u001b[39mappend(datum\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[39m# transform and load the line of indicator data\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     results \u001b[39m=\u001b[39m transform_indicator_data(data, colnames)\n\u001b[1;32m     15\u001b[0m     load_indicator_data(results)\n",
      "Cell \u001b[0;32mIn[3], line 69\u001b[0m, in \u001b[0;36mtransform_indicator_data\u001b[0;34m(data, colnames)\u001b[0m\n\u001b[1;32m     67\u001b[0m data_array\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m63\u001b[39m)\n\u001b[1;32m     68\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data_array, columns\u001b[39m=\u001b[39mcolnames)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mnan)\n\u001b[0;32m---> 69\u001b[0m df\u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39m\\r\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mIndicator Name\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mIndicator Code\u001b[39;49m\u001b[39m'\u001b[39;49m], inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     71\u001b[0m \u001b[39m# Reshape the data sets so that they are in long format\u001b[39;00m\n\u001b[1;32m     72\u001b[0m df_melt \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mmelt(id_vars\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mCountry Name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCountry Code\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     73\u001b[0m                     var_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     74\u001b[0m                     value_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgdp\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/dev/udacity/udacity-software-engineering-for-data-scientists/data_engineering/venv/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/dev/udacity/udacity-software-engineering-for-data-scientists/data_engineering/venv/lib/python3.8/site-packages/pandas/core/frame.py:5396\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5248\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   5249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5250\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5257\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5259\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5260\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5261\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5394\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5395\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5396\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5397\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5398\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5399\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5400\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5401\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5402\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5403\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5404\u001b[0m     )\n",
      "File \u001b[0;32m~/dev/udacity/udacity-software-engineering-for-data-scientists/data_engineering/venv/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/dev/udacity/udacity-software-engineering-for-data-scientists/data_engineering/venv/lib/python3.8/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/dev/udacity/udacity-software-engineering-for-data-scientists/data_engineering/venv/lib/python3.8/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/dev/udacity/udacity-software-engineering-for-data-scientists/data_engineering/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:6977\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6975\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6976\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6977\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6978\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6979\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['\\\\r\\\\n'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Execute this code cell to run the ETL pipeline\n",
    "# You do not need to change anything in this cell\n",
    "with open('../gdp_data.csv') as f:\n",
    "    for line in extract_lines(f):\n",
    "        data = line.split(',')\n",
    "        if len(data) == 63:\n",
    "            if data[0] == '\"Country Name\"':\n",
    "                colnames = []\n",
    "                # get rid of quote marks\n",
    "                for i, datum in enumerate(data):\n",
    "                    colnames.append(datum.replace('\"',''))\n",
    "            else:\n",
    "                # transform and load the line of indicator data\n",
    "                results = transform_indicator_data(data, colnames)\n",
    "                load_indicator_data(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this code cell to output the values in the gdp table\n",
    "# You do not need to change anything in this cell\n",
    "\n",
    "# connect to the database\n",
    "# the database file will be worldbank.db\n",
    "# note that sqlite3 will create this database file if it does not exist already\n",
    "conn = sqlite3.connect('worldbank.db')\n",
    "\n",
    "# get a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# create the test table including project_id as a primary key\n",
    "df = pd.read_sql(\"SELECT * FROM gdp\", con=conn)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2a8661282cfacf4edc05dcbaf70d4b702eaa37d9a94ad18ef8b5718413469be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
